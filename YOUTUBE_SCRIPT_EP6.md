# ðŸŽ¬ YouTube Script - Episode 6: "Building a Full-Featured LLM Chat App"

## ðŸ“ **Episode Title:**
"From Prompts to Conversations: Building an AI Chat App with Test-Driven Development"

## â±ï¸ **Duration:** 10 minutes

## ðŸŽ¯ **Episode Goal:**
Show how we transformed a simple prompt manager into a full-featured chat application using test-driven development and clean architecture principles.

---

## ðŸ“¹ **Script**

### **[00:00 - 00:30] INTRO** (30 seconds)

**[On Screen: Title Card]**

**YOU:**
> "Hey everyone! Welcome back to the series where we're building a Prompt Manager app with AI. I'm David, and today is a special episode - we're going from a simple prompt storage system to a full-featured chat application that rivals ChatGPT's interface."

**[Cut to: Screen recording showing old vs new UI side-by-side]**

**YOU:**
> "In the last episode, we got our template builder working after some debugging challenges. Today, we're adding the features that make this app actually useful: chat history, token tracking, conversation persistence, and more."

---

### **[00:30 - 01:30] THE CHALLENGE** (60 seconds)

**[On Screen: Design mockup / requirements]**

**YOU:**
> "So here's what we set out to build. We wanted a chat interface that gives users full control over their LLM interactions. That means:"

**[Bullet points appear on screen as you mention each:]**
- Model selection (GPT-4, GPT-3.5, etc.)
- Adjustable temperature and token limits
- Visual token tracking so you never hit limits
- Conversation history and persistence
- Customizable system prompts
- Clean, modern UI

**YOU:**
> "But here's the catch - we're doing this **test-first**. Every feature needs comprehensive tests before we write a single line of implementation code."

**[Show: Test count going from 0 â†’ 45]**

**YOU:**
> "By the end of this session, we have 45 tests passing. Let me show you how we got there."

---

### **[01:30 - 03:30] DESIGN DECISIONS** (2 minutes)

**[On Screen: Chat interface mockup]**

**YOU:**
> "First, we had to nail down the UI design. I wanted a clean, modern interface without the usual purple everyone uses. We went with blues and greens for a professional, trustworthy look."

**[Show: key_manager.html prototype]**

**YOU:**
> "For API key management, we created a dedicated settings page. Security is critical, so we made sure to communicate that keys are encrypted and stored locally."

**[Show: chat_interface.html prototype]**

**YOU:**
> "For the chat interface, we explored different layouts. I initially wanted a three-column design, but we realized that wasted valuable screen space. Instead, we put controls in a collapsible panel above the chat."

**[Demo: Toggle controls hide/show]**

**YOU:**
> "This gives users maximum flexibility - hide controls when chatting, show them when you need to adjust settings."

**[Show: Control panel with sliders]**

**YOU:**
> "The key insight here is separating settings by frequency of use:"
- **Static settings** (API keys) â†’ Settings page
- **Dynamic settings** (model, temperature) â†’ Top panel
- **Quick actions** (export, clear) â†’ Action buttons

**YOU:**
> "This makes the app feel intuitive because commonly-changed things are easy to reach."

---

### **[03:30 - 05:30] TEST-DRIVEN DEVELOPMENT** (2 minutes)

**[On Screen: Code editor showing test file]**

**YOU:**
> "Now let's talk about how we built this using test-driven development. Claude reminded me - and I'm glad he did - that we ALWAYS write tests first. Here's what that looks like in practice."

**[Show: test_chat_context_management.py]**

**YOU:**
> "We started with chat history. I wanted the LLM to remember previous messages in the conversation. So we wrote tests first:"

**[Highlight test code:]**
```python
def test_send_message_with_history(self, mock_manager, client):
    """Test that chat history is sent with new messages."""
    history = [
        {"role": "user", "content": "Hello"},
        {"role": "assistant", "content": "Hi there!"}
    ]
    
    response = client.post('/api/chat/send',
                          json={'message': 'How are you?', 'history': history})
    
    assert response.status_code == 200
    # Verify history was sent...
```

**YOU:**
> "These tests fail initially - that's the RED phase. Then we write just enough code to make them pass - the GREEN phase."

**[Show: Running pytest - tests failing]**
**[Show: Implementing the feature]**
**[Show: Running pytest - tests passing]**

**YOU:**
> "This approach means we have 100% confidence that our features work. No surprises, no regressions."

**[Show test results: 16 PASSED]**

**YOU:**
> "We did this for every feature: token tracking, system prompts, conversation persistence. Write test, watch it fail, make it pass, refactor if needed."

**[Show progression: 0 tests â†’ 17 tests â†’ 33 tests â†’ 45 tests]**

**YOU:**
> "By the end, we had 45 comprehensive tests covering all the new functionality."

---

### **[05:30 - 07:00] TOKEN TRACKING MAGIC** (90 seconds)

**[On Screen: Chat interface with token bar]**

**YOU:**
> "One of my favorite features is the token usage tracking. If you've ever hit OpenAI's context limit mid-conversation, you know how frustrating it is."

**[Demo: Start a conversation]**

**YOU:**
> "Watch this token bar as we chat."

**[Type and send several messages, showing bar fill]**

**YOU:**
> "It fills up in real-time, and the color changes from green to orange to red as you approach the limit."

**[Show: Bar at 85%, warning appears]**

**YOU:**
> "When you hit 80%, you get a warning. At 90%, the app automatically trims old messages to keep you under the limit."

**[Show: Auto-trim notification]**

**YOU:**
> "This is huge because it means you can have long, complex conversations without worrying about hitting walls. The app manages context for you."

**[Show code: calculate_token_usage function]**

**YOU:**
> "Under the hood, we're estimating tokens - about 4 characters per token - and tracking different context limits for different models. GPT-4 Turbo has 128,000 tokens, GPT-3.5 has 4,000. The app knows this and shows you exactly where you are."

---

### **[07:00 - 08:30] CONVERSATION PERSISTENCE** (90 seconds)

**[On Screen: conversations.json file]**

**YOU:**
> "Another critical feature: conversation persistence. Every chat is automatically saved."

**[Demo: Have a conversation]**

**YOU:**
> "Notice how after each exchange, you get a subtle notification. The conversation is being saved in the background."

**[Show: conversations.json file contents]**

**YOU:**
> "Conversations are stored as JSON with all the metadata: timestamps, model used, token counts, and of course all your messages."

**[Close browser, reopen]**

**YOU:**
> "If I close the browser and come back, I can reload any previous conversation and pick up right where I left off."

**[Show: API call to load conversation]**
```javascript
loadConversation('conv-abc123');
```

**YOU:**
> "The app even auto-titles conversations based on your first message, so you can easily find what you're looking for."

**[Show: List of conversations with titles]**

**YOU:**
> "This is where business logic separation really shines. We have a ConversationManager class that handles all the storage logic, completely separate from the UI."

**[Show: conversation_manager.py]**

**YOU:**
> "It's tested independently with 12 tests, so we know it works perfectly."

---

### **[08:30 - 09:30] CLEAN ARCHITECTURE** (60 seconds)

**[On Screen: Architecture diagram]**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UI (HTML/JS)       â”‚  â† Dumb, just renders
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Routes (Flask)     â”‚  â† Thin HTTP handlers
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Business Logic     â”‚  â† Testable managers
â”‚  - ChatManager      â”‚
â”‚  - TokenManager     â”‚
â”‚  - ConversationMgr  â”‚
â”‚  - LLMProviderMgr   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  External APIs      â”‚  â† OpenAI, etc.
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**YOU:**
> "This architecture is what makes the app maintainable. The UI is 'dumb' - it just displays data and captures input. All business logic lives in dedicated manager classes that are independently tested."

**[Show: Test coverage report]**

**YOU:**
> "This means when something breaks, we know exactly where to look. When we add features, we know they won't break existing functionality."

**[Show: LLMProviderManager with 100% coverage badge]**

**YOU:**
> "Some modules like the LLMProviderManager have 100% test coverage. Every single line is tested."

**[Show: Running full test suite]**

**YOU:**
> "And running all 45 tests takes less than a second. Fast feedback loop, high confidence."

---

### **[09:30 - 10:00] WHAT'S NEXT & WRAP-UP** (30 seconds)

**[On Screen: Refactoring plan preview]**

**YOU:**
> "So what's next? Well, we wrote a lot of code today - over 1,000 lines. Before we call this V1.0, we need to refactor."

**[Show: REFACTORING_PLAN.md highlights]**

**YOU:**
> "We'll extract more business logic from routes, consolidate our test suite, and add better error handling. The goal is to make this production-ready."

**[Show: Feature roadmap]**

**YOU:**
> "After that, we'll add prompt library integration, conversation history UI, and maybe even support for Claude and Gemini."

**[Cut to: You on camera]**

**YOU:**
> "The key lesson from today: **test-first development isn't slower, it's faster**. We never had to manually test anything. We never had to debug mysterious issues. The tests told us exactly what worked and what didn't."

**[On Screen: Call to action]**

**YOU:**
> "If you want to build along with me, all the code is on GitHub - link in the description. Leave a comment if you have feature suggestions or questions about the approach."

**YOU:**
> "Next episode, we'll do the refactoring and then wrap up V1.0. See you then!"

**[End screen with subscribe button]**

---

## ðŸŽ¨ **Visual Elements to Include**

### **B-Roll Footage:**
1. Code editor with tests running
2. Browser showing chat interface in action
3. Terminal output with green checkmarks
4. JSON files being updated
5. Architecture diagrams
6. Test coverage reports

### **Screen Recordings Needed:**
1. âœ… Settings page - adding API key
2. âœ… Chat interface - full conversation
3. âœ… Token bar filling up
4. âœ… Auto-trim notification
5. âœ… Conversation auto-save
6. âœ… System prompt customization
7. âœ… Model switching
8. âœ… Export conversation

### **Code Highlights:**
1. Test file showing test-first approach
2. ChatManager business logic
3. Token estimation algorithm
4. Message history building
5. Conversation persistence
6. Settings management

---

## ðŸ“Š **Key Statistics to Mention**

- **45 tests** written today
- **1,000+ lines** of code added
- **100% coverage** for business logic
- **4 OpenAI models** supported
- **128K tokens** max context (GPT-4 Turbo)
- **Auto-save** after every message
- **6 hours** of development (estimate)

---

## ðŸ’¡ **Key Takeaways for Audience**

### **Technical Lessons:**
1. **Test-first isn't optional** - It catches issues before they happen
2. **Separate UI from business logic** - Makes everything testable
3. **Start with user experience** - Design first, code second
4. **Iterate on design** - We created 3 UI prototypes before implementing
5. **Clean architecture pays off** - Easy to add features later

### **AI Pair Programming Lessons:**
1. **AI can forget your preferences** - Remind it about test-first!
2. **Clear requirements are critical** - Specific answers get better results
3. **Review AI code** - Don't blindly accept everything
4. **AI excels at boilerplate** - Tests, routes, managers
5. **Collaboration works** - Human vision + AI execution

---

## ðŸŽ­ **Tone & Style**

### **Overall Vibe:**
- Energetic but professional
- Educational without being preachy
- Show both wins and challenges
- Authentic "pair programming" feel

### **Pacing:**
- Quick intro (hook viewers)
- Detailed middle (educational content)
- Fast wrap-up (keep momentum)

### **Humor Opportunities:**
- "Claude forgot we do test-first... again!"
- "Token bars are like gas gauges for your AI"
- "We wrote more tests than implementation code - and that's a good thing!"

---

## ðŸ“š **Resources to Link**

### **In Description:**
1. GitHub repository
2. OpenAI API documentation
3. Test-driven development resources
4. Flask documentation
5. Previous episodes in series

### **On-Screen Links:**
- Blog post about architecture decisions
- Testing guide (TESTING_GUIDE.md)
- Refactoring plan (REFACTORING_PLAN.md)

---

## ðŸŽ¯ **Call to Action**

### **Primary CTA:**
> "Try building this yourself! Clone the repo and follow along."

### **Secondary CTA:**
> "What features should we add next? Comment below!"

### **Engagement:**
- Ask about their experience with TDD
- Poll: "Which model do you prefer - GPT-4 or GPT-3.5?"
- Request feature suggestions for V2.0

---

## ðŸ“¸ **Thumbnail Ideas**

### **Option A: Split Screen**
- Left: Code editor with tests
- Right: Beautiful chat UI
- Text: "Test-First Chat App"

### **Option B: Before/After**
- Before: Empty prompt manager
- After: Full chat interface
- Text: "45 Tests, 1000+ Lines, 1 Day"

### **Option C: Feature Showcase**
- Chat bubbles
- Token usage bar
- Settings page
- Text: "Build Your Own ChatGPT"

---

## ðŸ“ **Chapter Markers** (YouTube Timestamps)

```
00:00 - Introduction
00:30 - The Challenge
01:30 - Design Decisions
03:30 - Test-Driven Development in Action
05:30 - Token Tracking Magic
07:00 - Conversation Persistence
08:30 - Clean Architecture Benefits
09:30 - What's Next & Wrap-up
```

---

## ðŸŽ“ **Educational Value**

### **Viewers Will Learn:**
1. How to structure a Flask application
2. Test-driven development in practice
3. Separating business logic from UI
4. Working with LLM APIs
5. Token management strategies
6. Conversation state management
7. Building with AI pair programming

### **Skill Level:**
- **Beginner-friendly**: Clear explanations, visual examples
- **Intermediate-valuable**: Architecture patterns, testing strategies
- **Advanced-interesting**: Business logic separation, clean code

---

## ðŸ”¥ **Exciting Moments to Highlight**

### **"Wow" Moments:**
1. âš¡ Tests going from RED â†’ GREEN
2. ðŸŽ¨ Token bar changing colors in real-time
3. ðŸ’¾ Auto-save notification appearing
4. ðŸ”„ Context auto-trimming to prevent overflow
5. ðŸ“Š Test count: 45 PASSING
6. ðŸš€ First successful chat with history working

### **Learning Moments:**
1. ðŸ“š "We forgot to write tests first - had to backtrack"
2| ðŸ¤” "UI first vs business logic first debate"
3. ðŸ’¡ "Realizing token tracking prevents user frustration"
4. ðŸŽ¯ "Clean architecture makes testing trivial"

---

## ðŸ“º **Production Notes**

### **Recording Setup:**
- Screen: 1920x1080 minimum
- Editor + Browser visible
- Terminal window for tests
- Clear font size (14-16pt)

### **Editing Tips:**
- Speed up test runs (3x)
- Slow down UI interactions (0.75x)
- Add zoom for important code sections
- Use highlight boxes for key lines
- Background music (low volume)

### **Graphics Needed:**
- Architecture diagram
- Test pyramid graphic
- Before/after comparison
- Feature checklist (animated)

---

## ðŸŽ¬ **Alternate Versions**

### **Short Version** (5 minutes)
Focus on:
- Design decisions (1 min)
- Demo of features (2 min)
- Test-first benefits (1 min)
- Wrap-up (1 min)

### **Extended Version** (15 minutes)
Add:
- Deeper code walkthrough
- More testing examples
- Architecture discussion
- Q&A from previous episode

---

## ðŸ’¬ **Sample Dialog Snippets**

### **When Showing Tests:**
> "Look at this - we're testing that chat history gets sent with each message. The test creates a mock conversation, sends a new message, and verifies that all previous messages are included. This fails initially because we haven't implemented it yet. That's exactly what we want in TDD."

### **When Showing UI:**
> "Check out this token usage bar. It's not just pretty - it's functional. Users can see at a glance how much of their context window they're using. No more mysterious 'context length exceeded' errors."

### **When Showing Architecture:**
> "This is why separation of concerns matters. Our ConversationManager has zero dependencies on Flask, HTML, or UI code. It's pure business logic. We can test it in isolation, reuse it in different contexts, and maintain it easily."

### **When Discussing AI Pair Programming:**
> "Claude is like having a senior developer who never gets tired, never forgets patterns, and types faster than anyone. But you still need to guide it, review its work, and make architectural decisions. It's truly pair programming, not autopilot."

---

## ðŸŽ¯ **Success Metrics**

### **Video Performance Goals:**
- Views: 500+ in first week
- Watch time: >60% completion
- Likes: 50+
- Comments: 20+
- Shares: 10+

### **Audience Engagement:**
- Feature requests in comments
- Questions about TDD
- Requests for code review
- Interest in next episode

---

## âœ… **Pre-Recording Checklist**

- [ ] Server running smoothly
- [ ] Fresh database (no test data)
- [ ] API key ready (or mocked)
- [ ] Browser cache cleared
- [ ] Code formatted and clean
- [ ] Test suite passing
- [ ] Screen resolution set
- [ ] Recording software tested
- [ ] Script practiced
- [ ] Examples prepared

---

## ðŸŽ¬ **Final Notes**

### **What Makes This Episode Special:**
1. **Real development** - Not scripted, actual building
2. **Shows mistakes** - Forgot test-first, had to fix
3. **Practical TDD** - Not theory, actual practice
4. **Beautiful result** - Functional, modern app
5. **Complete story** - Problem â†’ Solution â†’ Working code

### **Differentiation:**
- Most coding videos: "Here's the final code"
- Our series: "Here's how we actually built it"
- Shows decision-making process
- Includes debugging and iteration
- Emphasizes testing and quality

---

## ðŸš€ **Closing Thought**

**YOU:**
> "Building software with AI is transforming how we code. It's not about AI replacing developers - it's about developers with AI building better software faster. This app took us one day. Traditional development? Probably a week. And we have better test coverage than most production apps."

> "That's the power of modern development: great tools, clean architecture, and test-driven discipline. See you next time!"

---

**[END CARD: 10 seconds]**
- Subscribe button
- Next video preview
- GitHub link
- Comment prompt

---

## ðŸ“Š **Episode Stats Summary**

**What We Built:**
- Full chat interface
- 4 business logic managers  
- 45 comprehensive tests
- Token tracking system
- Conversation persistence
- System prompt customization
- API key management
- Model selection (4 models)

**Lines of Code:**
- Implementation: ~1,200 lines
- Tests: ~800 lines
- Total: ~2,000 lines in one day

**Test Coverage:**
- 45 tests passing
- 0 tests failing
- 100% coverage for business logic
- Test-first approach throughout (after reminder!)

---

**Ready to record! This will be an engaging, educational episode that showcases real software development.** ðŸŽ¥
